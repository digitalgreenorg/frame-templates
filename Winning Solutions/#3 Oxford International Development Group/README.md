# Crop Yield Prediction with XYieldBoost 
*A machine learning model for improving precision agriculture in Bihar, India*

### Introduction

Hello! We are the Oxford International Development Group, a team of researchers using machine learning to advance international development.

**Jessica Rapson** – Jessica has a Master of Public Policy from the University of Toronto and a Master of Statistical Science from the University of Oxford. Her work involves developing machine learning tools for governments.

**Shaw Chifamba** – Shaw is a Machine Learning Solutions Architect for UNECE working to improve agricultural supply chains using ML. He is also studying for a Master in Precision Cancer Medicine at the University of Oxford.

**Juliette Zaccour** – Juliette is a Social Data Science DPhil student at the University of Oxford with a background in human-centred data science. Her research focuses on algorithmic justice and auditing methods for public sector systems.

### Problem

Smallholder farmers in Bihar, India struggle with resource constraints and unpredictable weather that limits food security. Developing a machine learning (ML) model to accurately predict crop yield can empower these farmers to make informed agricultural decisions, reducing poverty and malnutrition.

### Introducing XYieldBoost

Our model, XYieldBoost, leverages agricultural knowledge and tree-based ML to improve crop yield predictions.

- **Easy to Implement and Run**:  Smart feature engineering is directly applied to Digital Green survey data, enabling fast training and program integration

- **Improves Crop Yield Prediction Accuracy**: Prediction generated by XYieldBoost reduce crop yield prediction error by 72\% compared to benchmark estimates

- **Provides Insights for Crop Yield Improvements**: Estimates of variable importance and quantifications of variable impacts for specific predictions enables actionable insights on improving yield

This README file covers:
- Our submission folder structure
- How to run our model and the expected runtime
- The description of our process and training features

### Folder Structure

- The ```data``` folder includes the datasets provided for this competition
- The ```xyieldboost.ipynb``` notebook is the end-to-end reproducible model
- The ```requirements.txt``` file allows to ensure all required packages are installed when running the notebook
- The ```pipeline``` folder includes the preprocessing .py files (cleaning.py, feature_engineering.py, scaling.py, feature_selection.py, dim_reduction.py and clustering.py)
- The ```predictions.csv``` file is output by the model and includes IDs and Yield predictions for the test set.

### Running the Model

XYieldBoost can easily be run using Google Colab:
- Import the ```XYieldBoost``` folder into Google Drive
- Open the ```xyieldboost.ipynb``` notebook using Google Colab
- Replace the directory path in the first cell with the location of the folder in your Google Drive ```\%cd '/content/gdrive/My Drive/XYieldBoost'```
- Predictions will be exported as ```predictions.csv```

**The expected runtime is around 5-6 minutes** (in Google Colab)
- Note: Due to the nature of the models we used (XGBoost, LightGBM and CatBoost), the predictions will slightly vary with every run. Setting a seed does not allow for exact reproducibility due to inherent properties of these models, but we have verified through extensive tests that RMSE of XYieldBoost is stable. 

### Creating XYieldBoost

1) **Cleaning**: We obtained months from datetime columns, fixed suspected entry errors both for predictors and the outcome variable, pased messy categorical variables, imputed missing values, and processed outliers by capping variables at reasonable values
2) **Feature engineering**: We divided certain predictors by the ```Acre``` variable where relevant, capped additional per acre outliers with reasonable values, added binary variables indicating missing inputs where these were meaningful, added variables indicating the number of days between key agricultural processes, encoded differences from average values in the training data as a feature, merged low frequency variables with similar variables, encoded months and seasons as categorical variables, and encoded how many fertilizers were used
3) **Scaling**: We one-hot encoded categorical variables, min-max scaled  discrete variables, and standard scaled for continuous variables
4) **Initial feature selection**: We dropped unprocessed variables from which other meaningful variables were derived (e.g. raw dates) and categortical variables with less than 20 responses
5) **Dimensionality reduction**: We applied principal component analysis to extract 21 principal components from the dataset
6) **Clustering**: We produced k-means clusters for values of k ranging from 2 to 5, using different sets of features to capture latent patterns in the data that might indicate different crop types or agricultural practices that are not explictly encoded as features
7) **Secondary feature selection**: We selected the final list of features, ```top_cols```, using recursive feature elimination with five-fold cross-validation using a baseline XGBoost model
9) **Modeling**: We took the average of five-fold cross-validation predictions made from XGBoost, LightGBM, and CatBoost models to predict the yield per acre for a given plot of land
10) **Prediction**: The model trained on the entirety of the test data produced predictions of yield per acre for the unseen the test set
11) **Post-processing**: 

### More About XYieldBoost

We used an ensemble method that took the average of three predictions made using tree-based methods, specifically: XGBoost, CatBoost, and LightGBM. All three are tree-based methods, which are efficient for handling tabular data with non-linear relationships. We also used cross validation to train and test our model in order to reduce overfitting.

However, the most important part of our analysis lies at the data exploration and data cleaning stages. We spent 95\% of our time on data exploration, cleaning and feature engineering, which involved understanding the data and reading literature on which variables affect crop yield in Bihar, and India more generally.

As a result, we learned about different agricultural traditions in North Bihar vs. South Bihar (which is more agriculturally productive and employs the Ahar Pyne agricultural system, leveraging channels and retention ponds to manage water resources and adapt to Bihar’s unpredictable weather). We also learned about the importance of the monsoon in Bihar agricultural cycles. Kharif crops, such as rice, are sown during the monsoon season from June to September and are watered by monsoon rainfall. These crops do well with high rain in Winter. We also learned about nitrogen cycles, fertilizer application methods, and irrigation techniques.

This background research allowed us to realize that the region in which the crops was grown was important (North vs. South Bihar), as were the various dates on which key agricultural steps were taken and fertilisation choices. We engineered our data to reflect this, and selected the top variables using recursive feature elimination with cross validation.

The remaining 5\% of our time was spent building and fine-tuning the model. We believe the key strategy was to understand the data and which features were important for predictions, and avoid overfitting to the public test set. The importance of feature engineering in creating this model is indicated by the high percentage of engineered features that were selected by recursive feature elimination and ended up in the final model.

### Training Features Used

#### Original Features
- ```SeedlingsPerPit```: The number of seedlings planted per pit
- ```Ganaura```: The amount of Ganaura (in quintals) applied as organic fertiliser
- ```CropOrgFYM```: The amount of farmyard manue applied as organic fertiliser
- ```NoFertilizerAppln```: The number of times chemical fertilizer was been applied in the entire crop cycle
- ```BasalDAP```: The amount of di-ammonium phosphate (in kgs) applied during land preparation
- ```BasalUrea```: The amount of urea (in kgs) applied during land preparation
- ```2appDaysUrea```: The number of days between the second and third dose of urea
- ```Harv_hand_rent```: The rent (in rupees) for labourers or machining used in harvesting
- ```Residue_length```: The length of the residue left after harvesting

#### Engineered Features
- ```TransplantingIrrigationHours_per_Acre```: The number of hours spent on irrigation during transplantation divided by acre
- ```TransIrriCost_per_Acre```: The cost of irrigation during transplantation divided by acre
- ```CropOrgFYM_per_Acre```: The amount of farmyard manure applied as organic fertiliser divided by acre
- ```BasalDAP_per_Acre```: The amount of di-ammonium phosphate applied as basal fertiliser divided by acre
- ```BasalUrea_per_Acre```: The amount of urea applied as basal fertiliser divided by acre
- ```1tdUrea_per_Acre```: The amount of urea applied in the second dose divded by area
- ```Harv_hand_rent_per_Acre```: The rent (in rupees) for labourers or machining used in harvesting divided by acre
- ```TpIrrigationCost_Imputed_per_Acre```: The cost of irrigation during transplantation divided by acre, with missing values replaced by the training data median
- ```Days_bw_SowTransp_Harv```: The number of days between sowing/transplanting and harvesting
- ```Days_bw_Harv_Thresh```: The number of days between harvesting and threshing
- ```NursingDate_ModeDiff```: The difference in days between the nursing date and the training data mode nursing date
- ```TillageDate_ModeDiff```: The difference in days between the tillage date and the training data mode tillage date
- ```HarvestDate_ModeDiff```: The difference in days between the harvest date and the training data mode harvest date
- ```ThreshingDate_ModeDiff```: The difference in days between the threshing data and the traing data mode threshing date
- ```Num_LandPrepMethod```: The number of methods used to prepare land for crops
- ```Num_CropbasalFerts```: The number of basal fertilisers used
- ```Num_TopDressFert```: The number number of chemical fertilisers applied in the second dose
- ```Latitude```: The latitude coordinate of the block
- ```Longitude```: The longitude coordinate of the block
- ```CropEstMethod_LineSowingAfterTillage```: Whether line sowing after tillage was used as method of transplantation
- ```Threshing_method_machine```: Whether threshing was done with a machine (as opposed to by hand)
- ```Stubble_use_plowed_in_soil```: Whether plowing in soil was used for stubble (as opposted to burning)
- ```LandPrepMethod_FourWheelTracRotavator_True```: Whether a four wheel tractor rotavator was used in land preparation
- ```LandPrepMethod_WetTillagePuddling_True```: Whether wet tillage puddling was used in land preparation
- ```NursDetFactor_PreMonsoonShowers_True```: Whether "Pre Monsoon Showers" was selected as a reason for choosing the Nursing Date
- ```NursDetFactor_LabourAvailability_True```: Whether "Labour Availability" was selected as a reason for choosing the Nursing Date
- ```FirstTopDressFert_DAP_True```: Whether di-ammonium phosphate fertiliser was applied for the second dose of fertiliser
- ```HarvestMonth_November```: Whether harvesting was done in November
- ```ThreshingMonth_January```: Whether threshing was done in January
- ```Block_Chehrakala```: Whether the Block is Chehrakala
- ```PCropSolidOrgFertAppMethod_Broadcasting```: Whether organic fertiliser was applied using broadcasting in the previous crop cycle
- ```PCropSolidOrgFertAppMethod_SoilApplied```: Whether organic fertiliser was applied to the soil in the previous crop cycle
- ```MineralFertAppMethod_1_Broadcasting```: Whether organic fertiliser was applied using broadcasting in the current crop cycle
- ```MineralFertAppMethod_1_SoilApplied```: Whether organic fertiliser was applied to the soil in the current crop cycle
- ```PC4```: The 4th principal component from the original set of features
- ```PC10```: The 10th principal component from the original set of features
- ```PC21```: The 21st principal component from the original set of features
- ```top_shapley_k2_label_1```: Whether the farm is part of the first cluster in the k=2 k-means clustering model that uses the variables with the top Shapley values from the original set of features